{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import json\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 优先使用GPU\n",
    "\n",
    "\n",
    "def read_json(file_path):\n",
    "    '''读取 json 文件'''\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_json(data, path):\n",
    "    '''写入 json 文件'''\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "\n",
    "\n",
    "raw_data = read_json('input/query_trainset.json')\n",
    "data = [item for item in raw_data if item['evidence_list'] != []]\n",
    "\n",
    "\n",
    "class CustomLSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3):\n",
    "        super(CustomLSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.attn = nn.Linear(hidden_dim * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_dim).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        attn_weights = torch.nn.functional.softmax(self.attn(out), dim=1)\n",
    "        attn_output = torch.sum(attn_weights * out, dim=1)\n",
    "        output = self.fc(attn_output)\n",
    "        return output\n",
    "\n",
    "\n",
    "def jaccard_similarity(query_embedding, document_embeddings):\n",
    "    intersection = torch.sum(query_embedding * document_embeddings, dim=1)\n",
    "    union = torch.sum(query_embedding + document_embeddings > 0, dim=1)\n",
    "    jaccard = intersection / (union + 1e-8)  # 加上一个小值以避免除以零\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def retrieve_top_k_documents(query_embedding, document, model, k=3):\n",
    "    with torch.no_grad():\n",
    "        query_embedding = query_embedding.unsqueeze(0)\n",
    "        document_embeddings = torch.stack([torch.tensor(item['facts_embedding'], device=device) for item in document])\n",
    "\n",
    "        predict_embedding = model(query_embedding)\n",
    "        cosine_similarities = F.cosine_similarity(predict_embedding, document_embeddings, dim=-1)\n",
    "        jaccard_similarities = jaccard_similarity(query_embedding, document_embeddings)\n",
    "\n",
    "        combined_scores = 0.5 * cosine_similarities + 0.5 * jaccard_similarities\n",
    "\n",
    "        _, top_document_indices = combined_scores.topk(k)\n",
    "        return top_document_indices.tolist()\n",
    "\n",
    "\n",
    "input_size = 1024\n",
    "hidden_size = 128\n",
    "output_size = 1024\n",
    "model = CustomLSTMModel(input_size, hidden_size, output_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 1500\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for item in data:\n",
    "        query_embedding = torch.tensor(item['query_embedding'], dtype=torch.float32).to(device)\n",
    "        evidence_embeddings = torch.stack(\n",
    "            [torch.tensor(doc['fact_embedding'], dtype=torch.float32).to(device) for doc in item['evidence_list']])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        query_embedding = query_embedding.unsqueeze(0)\n",
    "\n",
    "        output = model(query_embedding)\n",
    "        if evidence_embeddings.numel() > 0:\n",
    "            loss = criterion(output, evidence_embeddings.mean(dim=0).unsqueeze(0))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss / len(data)}')\n",
    "\n",
    "test = read_json('input/query_testset.json')\n",
    "document = read_json('input/document.json')\n",
    "\n",
    "results = []\n",
    "for item in tqdm.tqdm(test):\n",
    "    result = {}\n",
    "    test_embedding = torch.tensor(item['query_embedding'], device=device)\n",
    "    top_document_indices = retrieve_top_k_documents(test_embedding, document, model, k=3)\n",
    "    result['query_input_list'] = item['query_input_list']\n",
    "    result['evidence_list'] = [{'fact_input_list': document[index]['fact_input_list']} for index in\n",
    "                               top_document_indices]\n",
    "    results.append(result)\n",
    "\n",
    "write_json(results, 'output/result.json')\n",
    "print('写入到 output/result.json 成功')\n",
    "\n",
    "\n",
    "def zip_fun():\n",
    "    path = os.getcwd()\n",
    "    newpath = path + \"/output/\"\n",
    "    os.chdir(newpath)\n",
    "    os.system('zip prediction.zip result.json')\n",
    "    os.chdir(path)\n",
    "\n",
    "\n",
    "zip_fun()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
